{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "#panda is a read/write tool\n",
    "\n",
    "train_file = \"c:\\\\kaggle\\\\digit_recog\\\\train.csv\"\n",
    "test_file = \"c:\\\\kaggle\\\\digit_recog\\\\test.csv\"\n",
    "\n",
    "drData = pd.read_csv(train_file, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "drData = pd.read_csv(train_file, header = 0)\n",
    "images = drData.iloc[0:10000,1:]\n",
    "labels = drData.iloc[0:10000,:1]\n",
    "#images[images > 0] = 255\n",
    "#images[images <= 0] = 0\n",
    "images = images / 255\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryMlpBestActSolver(actList, sovList):\n",
    "    for idx1, val1 in enumerate(actList):\n",
    "        for idx2, val2 in enumerate(sovList):\n",
    "            mlp = MLPClassifier(activation=val1, solver=val2)\n",
    "\n",
    "            mlp.fit(X_train, y_train.values.ravel())\n",
    "            X_test_predict = mlp.predict(X_test)\n",
    "\n",
    "            #print(mlp)\n",
    "            print(\"Score of activation %s, solver %s: %s\\n\" % (val1, val2, mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actList = ['identity', 'logistic', 'tanh', 'relu']\n",
    "sovList = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "tryMlpBestActSolver(actList, sovList)\n",
    "'''\n",
    "Score of activation identity, solver lbfgs: 0.88\n",
    "Score of activation identity, solver sgd: 0.91\n",
    "Score of activation identity, solver adam: 0.902\n",
    "Score of activation logistic, solver lbfgs: 0.9372\n",
    "Score of activation logistic, solver sgd: 0.8776\n",
    "Score of activation logistic, solver adam: 0.9448\n",
    "Score of activation tanh, solver lbfgs: 0.94\n",
    "Score of activation tanh, solver sgd: 0.9144\n",
    "Score of activation tanh, solver adam: 0.9476\n",
    "Score of activation relu, solver lbfgs: 0.942\n",
    "Score of activation relu, solver sgd: 0.9228\n",
    "Score of activation relu, solver adam: 0.9464\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryMlpBestHiddenLayer(hList):\n",
    "    for idx, val in enumerate(hList):\n",
    "        mlp = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=val)\n",
    "\n",
    "        mlp.fit(X_train, y_train.values.ravel())\n",
    "        X_test_predict = mlp.predict(X_test)\n",
    "\n",
    "        #print(mlp)\n",
    "        print(\"Score of hidden Layer %s: %s\\n\" % (val, mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hList = [10,50,100,500,1000,2000]\n",
    "\n",
    "tryMlpBestHiddenLayer(hList)\n",
    "\n",
    "'''\n",
    "relu, lbfgs\n",
    "Score of hidden Layer 10: 0.878\n",
    "Score of hidden Layer 50: 0.9384\n",
    "Score of hidden Layer 100: 0.946\n",
    "Score of hidden Layer 500: 0.9508\n",
    "Score of hidden Layer 1000: 0.9528\n",
    "Score of hidden Layer 2000: 0.9536\n",
    "\n",
    "relu, adam\n",
    "Score of hidden Layer 10: 0.9128\n",
    "Score of hidden Layer 50: 0.946\n",
    "Score of hidden Layer 100: 0.9476\n",
    "Score of hidden Layer 500: 0.9568\n",
    "Score of hidden Layer 1000: 0.9568\n",
    "Score of hidden Layer 2000: 0.9584\n",
    "Score of hidden Layer 3000: 0.9132\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryMlpBestLearningRate(rlList):\n",
    "    for idx, val in enumerate(rlList):\n",
    "        mlp = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=2000, learning_rate_init=val)\n",
    "\n",
    "        mlp.fit(X_train, y_train.values.ravel())\n",
    "        X_test_predict = mlp.predict(X_test)\n",
    "\n",
    "        #print(mlp)\n",
    "        print(\"Score of learning rate init %s: %s\\n\" % (val, mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlList = [0.1,0.01,0.001,0.0001,0.00001]\n",
    "\n",
    "tryMlpBestLearningRate(rlList)\n",
    "\n",
    "'''\n",
    "Score of learning rate init 0.1: 0.8924\n",
    "Score of learning rate init 0.01: 0.9432\n",
    "Score of learning rate init 0.001: 0.9552\n",
    "Score of learning rate init 0.0001: 0.9524\n",
    "Score of learning rate init 1e-05: 0.9272\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryMlpBestBatchSize(btList):\n",
    "    for idx, val in enumerate(btList):\n",
    "        mlp = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=2000, learning_rate_init=0.001, batch_size=val)\n",
    "\n",
    "        mlp.fit(X_train, y_train.values.ravel())\n",
    "        X_test_predict = mlp.predict(X_test)\n",
    "\n",
    "        #print(mlp)\n",
    "        print(\"Score of batch size %s: %s\\n\" % (val, mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btList = [100,200,400,800]\n",
    "\n",
    "tryMlpBestBatchSize(btList)\n",
    "\n",
    "\n",
    "'''\n",
    "Score of batch size 100: 0.9648\n",
    "Score of batch size 200: 0.964\n",
    "Score of batch size 400: 0.9632\n",
    "Score of batch size 800: 0.9604\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryMlpBestAlpha(ahList):\n",
    "    for idx, val in enumerate(ahList):\n",
    "        mlp = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=2000, learning_rate_init=0.001, batch_size=200, alpha=val)\n",
    "\n",
    "        mlp.fit(X_train, y_train.values.ravel())\n",
    "        X_test_predict = mlp.predict(X_test)\n",
    "\n",
    "        #print(mlp)\n",
    "        print(\"Score of alpha %s: %s\\n\" % (val, mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahList = [0.01,0.001,0.0001,0.00001]\n",
    "\n",
    "tryMlpBestAlpha(ahList)\n",
    "\n",
    "'''\n",
    "Score of alpha 0.01: 0.9798095238095238\n",
    "Score of alpha 0.001: 0.9717142857142858\n",
    "Score of alpha 0.0001: 0.9814285714285714\n",
    "Score of alpha 1e-05: 0.982\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryMlpMaxIter(miList):\n",
    "    for idx, val in enumerate(miList):\n",
    "        mlp = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=2000, learning_rate_init=0.001, batch_size=200, alpha=0.001, max_iter=val)\n",
    "\n",
    "        mlp.fit(X_train, y_train.values.ravel())\n",
    "        X_test_predict = mlp.predict(X_test)\n",
    "\n",
    "        print(mlp)\n",
    "        print(\"Score of Max Iter %s: %s\\n\" % (val, mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miList = [100,200,400,800]\n",
    "\n",
    "tryMlpMaxIter(miList)\n",
    "\n",
    "'''\n",
    "Score of Max Iter 100: 0.9636\n",
    "Score of Max Iter 200: 0.964\n",
    "Score of Max Iter 400: 0.964\n",
    "Score of Max Iter 800: 0.9648\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryScaleAffection(scaleList):\n",
    "    for idx, val in enumerate(scaleList):\n",
    "        drData = pd.read_csv(train_file, header = 0)\n",
    "        images = drData.iloc[0:val,1:]\n",
    "        labels = drData.iloc[0:val,:1]\n",
    "        #images[images > 0] = 255\n",
    "        #images[images <= 0] = 0\n",
    "        images = images / 255\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(images, labels)\n",
    "\n",
    "        mlp = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=2000, learning_rate_init=0.001, batch_size=200, alpha=0.00001, max_iter=800)\n",
    "\n",
    "        mlp.fit(X_train, y_train.values.ravel())\n",
    "        X_test_predict = mlp.predict(X_test)\n",
    "\n",
    "        print(mlp)\n",
    "        print(\"Score of scale %d: %s\\n\" % (val, mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleList = [20000,30000,40000]\n",
    "\n",
    "tryScaleAffection(scaleList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drData = pd.read_csv(train_file, header = 0)\n",
    "images = drData.iloc[0:41999,1:]\n",
    "labels = drData.iloc[0:41999,:1]\n",
    "#images[images > 0] = 255\n",
    "#images[images <= 0] = 0    \n",
    "images = images / 255\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels)\n",
    "\n",
    "mlp = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes=2000, learning_rate_init=0.001, batch_size=200, alpha=0.0001, max_iter=800)\n",
    "\n",
    "mlp.fit(X_train, y_train.values.ravel())\n",
    "X_test_predict = mlp.predict(X_test)\n",
    "\n",
    "print(mlp)\n",
    "print(\"Score: %s\\n\" % (mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drTest = pd.read_csv(test_file, header = 0)\n",
    "\n",
    "drTest_predict = mlp.predict(drTest)\n",
    "\n",
    "# compare with the almost data\n",
    "almost_perfect_file = \"c:\\\\kaggle\\\\digit_recog\\\\almost_perfect.csv\"\n",
    "almostPref = pd.read_csv(almost_perfect_file, header = 0)\n",
    "alpSurv = almostPref['Label']\n",
    "\n",
    "idx = 0\n",
    "okay = 0\n",
    "for ti_pred in drTest_predict:\n",
    "    if ti_pred == alpSurv.iloc[idx]:\n",
    "        okay += 1\n",
    "    idx += 1\n",
    "\n",
    "print(okay)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file = 'c:\\\\kaggle\\\\digit_recog\\\\submission_mlp_' + str(okay) + '.csv'\n",
    "print(submit_file)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        'ImageId': list(range(1,len(drTest_predict)+1)), \n",
    "        'Label': drTest_predict\n",
    "    })\n",
    "\n",
    "submission.to_csv(submit_file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with the almost data\n",
    "predict_file = \"c:\\\\kaggle\\\\digit_recog\\\\submission_mlp_demo.csv\"\n",
    "predictPd = pd.read_csv(predict_file, header = 0)\n",
    "predict = predictPd['Label']\n",
    "\n",
    "almost_perfect_file = \"c:\\\\kaggle\\\\digit_recog\\\\almost_perfect.csv\"\n",
    "almostPref = pd.read_csv(almost_perfect_file, header = 0)\n",
    "alpSurv = almostPref['Label']\n",
    "\n",
    "idx = 0\n",
    "okay = 0\n",
    "for pred in predict:\n",
    "    if pred == alpSurv.iloc[idx]:\n",
    "        okay += 1\n",
    "    idx += 1\n",
    "\n",
    "print(okay)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
